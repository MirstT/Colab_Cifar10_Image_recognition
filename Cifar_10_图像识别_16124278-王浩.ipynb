{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yK6tx3k3blhW"
   },
   "source": [
    "\n",
    "# 16124278 王浩 week 3 \n",
    "Cifar_10_图像识别 由于数据集较大且训练模型较为复杂，可训练参数多达142万，\n",
    "即使在本地使用GPU（MX150）运行仍需接近一天时间，\n",
    "故本程序借助Google Colab利用GPU加速（约1h）在云端运行。\n",
    "\n",
    "最终在训练集上的准确率为：96.88%   验证集上的准确率为：97.05%   测试集上的准确率为：96.97%\n",
    "\n",
    "*注：由于暂时无法在colab中引用本地图片，文中所有图片均为本地图片上传至GitHub后的网页链接*\n",
    "\n",
    "[本地图片链接（GitHub）](https://github.com/MirstT/Colab_Cifar10_Image-recognition/)\n",
    "## 打印Colab目前连接使用机器（GPU）信息\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "colab_type": "code",
    "id": "DkvdQuRAavXd",
    "outputId": "9dbc8bdd-4de7-4170-82f2-69c0e360965a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gputil in /usr/local/lib/python3.6/dist-packages (1.4.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
      "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
      "Gen RAM Free: 11.3 GB  | Proc size: 143.1 MB\n",
      "GPU RAM Free: 3039MB | Used: 8402MB | Util  73% | Total 11441MB\n"
     ]
    }
   ],
   "source": [
    "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
    "!pip install gputil\n",
    "!pip install psutil\n",
    "!pip install humanize\n",
    "import psutil\n",
    "import humanize\n",
    "import os\n",
    "import GPUtil as GPU\n",
    "GPUs = GPU.getGPUs()\n",
    "gpu = GPUs[0]\n",
    "def printm():\n",
    " process = psutil.Process(os.getpid())\n",
    " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
    " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
    "\n",
    "#打印相关信息\n",
    "printm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iO_7KHYAcASL"
   },
   "source": [
    "## 建立ipynb与Google云盘的连接\n",
    "将训练模型以及日志文件储存在自己的云盘文件中，\n",
    "同时方便以后使用本地数据集/本地模板库。\n",
    "\n",
    "![alt text](https://github.com/MirstT/Colab_Cifar10_Image-recognition/blob/master/res/WH_2019-04-09_08-08-39.png?raw=true)\n",
    "\n",
    "登录代码：\n",
    "\n",
    "![alt text](https://github.com/MirstT/Colab_Cifar10_Image-recognition/blob/master/res/WH_2019-04-09_16-14-21.png?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "id": "HznycZWvcIBs",
    "outputId": "4cd91633-3486-4ce8-e127-b0d49d3621e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: Package 'python-software-properties' has no installation candidate\n",
      "Selecting previously unselected package google-drive-ocamlfuse.\n",
      "(Reading database ... 131304 files and directories currently installed.)\n",
      "Preparing to unpack .../google-drive-ocamlfuse_0.7.3-0ubuntu1~ubuntu18.04.1_amd64.deb ...\n",
      "Unpacking google-drive-ocamlfuse (0.7.3-0ubuntu1~ubuntu18.04.1) ...\n",
      "Setting up google-drive-ocamlfuse (0.7.3-0ubuntu1~ubuntu18.04.1) ...\n",
      "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
      "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
      "··········\n",
      "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
      "Please enter the verification code: Access token retrieved correctly.\n"
     ]
    }
   ],
   "source": [
    "# 安装相关文件\n",
    "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
    "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
    "!apt-get update -qq 2>&1 > /dev/null\n",
    "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
    "\n",
    "# 账号信息授权\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "#授权码1\n",
    "#4/JwE_0WWiynLrN7mj3bfRDFe6R4jhjc2hKcSb59vXE816ZAyt2kCyjXM\n",
    "\n",
    "# 账号密码授权\n",
    "from oauth2client.client import GoogleCredentials\n",
    "creds = GoogleCredentials.get_application_default()\n",
    "import getpass\n",
    "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
    "vcode = getpass.getpass()\n",
    "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n",
    "#授权码2\n",
    "#4/JwHPn1brf-kYZU5L6pmu4XsF7Ckdhs-h9aXh93BLCYk-bMQKa1r-dks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BRNOLbiwqPrj"
   },
   "source": [
    "## Google云盘工作文件夹设置\n",
    "显示工作目录下的内容（和linux系统下命令基本相同）\n",
    "![alt text](https://github.com/MirstT/Colab_Cifar10_Image-recognition/blob/master/res/WH_2019-04-09_15-36-19.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "id": "6Fz3r1dogQIn",
    "outputId": "a9078408-1c28-477d-f03e-c440ca75a838"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Advanced_Data_Analysis\t\t      models\n",
      "'Advanced_Data_Analysis (28c5583b)'  'models (5069b798)'\n",
      " char-09.ipynb\t\t\t      old_Cifar_10_图像识别.ipynb\n",
      " logs\t\t\t\t      WH_2019-04-09_08-08-39.png\n",
      "'logs (36bf767a)'\t\t      wh_drive\n",
      " mnist_mlp.ipynb\n"
     ]
    }
   ],
   "source": [
    "# 指定Google Drive云端硬盘的根目录，名为wh_drive\n",
    "!mkdir -p wh_drive\n",
    "!google-drive-ocamlfuse wh_drive\n",
    "\n",
    "\n",
    "# 指定当前的工作文件夹\n",
    "import os\n",
    "os.chdir(\"wh_drive/Colab\") \n",
    "\n",
    "\n",
    "# 显示工作目录下的内容\n",
    "! ls "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wVUjk4lb7Lj-"
   },
   "source": [
    "## Cifar10数据集下载导入与归一化\n",
    "服务器网速很快，不需要从云盘中读取数据集，直接下载到colab服务器运行即可"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "9UFA0AEIhDJM",
    "outputId": "20c4bbe4-d4fa-4148-ca1b-90019ab0fed9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 14s 0us/step\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#设置随机种子\n",
    "np.random.seed(161)\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "\n",
    "#读取数据集\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "#归一化\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CqTpjQP97xiz"
   },
   "source": [
    "## Cifar10数据预处理\n",
    "将彩色图片转为灰度图片：\n",
    "灰度值 = 0.2989 * 红色 + 0.5870 * 绿色 + 0.1140 * 蓝色"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 515
    },
    "colab_type": "code",
    "id": "1NQbPEnNhpTD",
    "outputId": "ffc3c8f1-43e2-40fb-8fba-0f3a647545cc"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD5CAYAAAAOeCiTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD5CAYAAAAOeCiTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#选取彩色通道，将图片转换为灰度图\n",
    "x_train_gray = np.dot(x_train[:,:,:,:3], [0.299, 0.587, 0.114])\n",
    "x_test_gray = np.dot(x_test[:,:,:,:3], [0.299, 0.587, 0.114])\n",
    "\n",
    "#大小统一为32*32像素\n",
    "x_train_gray = x_train_gray.reshape(-1,32,32,1)\n",
    "x_test_gray = x_test_gray.reshape(-1,32,32,1)\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "y_train_cat = to_categorical(y_train)\n",
    "y_test_cat = to_categorical(y_test)\n",
    "\n",
    "plt.imshow(x_train[1])\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(x_train_gray[1,:,:,0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GrdTStoIeQw3"
   },
   "source": [
    "## 模型搭建（基于Inception架构）\n",
    "获得高质量模型最保险的做法就是增加模型的深度（层数）或者是其宽度（层核或者神经元数），\n",
    "\n",
    "但是一般设计思路的情况下会出现如下的缺陷：\n",
    "\n",
    "1.参数太多，若训练数据集有限，容易过拟合；\n",
    "\n",
    "2.网络越大计算复杂度越大，难以应用；\n",
    "\n",
    "3.网络越深，梯度越往后穿越容易消失，难以优化模型。 \n",
    "\n",
    "\n",
    "解决上述两个缺点的根本方法是将全连接甚至一般的卷积都转化为稀疏连接。\n",
    "\n",
    "## Inception架构的主要思想是找出如何用密集成分来近似最优的局部稀疏结。\n",
    "![alt text](https://github.com/MirstT/Colab_Cifar10_Image-recognition/blob/master/res/WH_2019-04-09_17-29-26.png?raw=true)\n",
    "\n",
    "1.   采用不同大小的卷积核意味着不同大小的感受野，最后拼接意味着不同尺度特征的融合；\n",
    "2.   之所以卷积核大小采用1*1、3*3和5*5，主要是为了方便对齐。设定卷积步长stride=1之后，只要分别设定padding =0、1、2，采用same卷积可以得到相同维度的特征，然后这些特征直接拼接在一起； \n",
    "3.   很多论文都表明pooling挺有效，所以Inception里面也嵌入了pooling。\n",
    "4.   减少计算成本，采用1x1卷积核来进行降维\n",
    "\n",
    "Inception的作用：代替人工确定卷积层中的过滤器类型或者确定是否需要创建卷积层和池化层，即：不需要人为的决定使用哪个过滤器，是否需要池化层等，由网络自行决定这些参数，可以给网络添加所有可能值，将输出连接起来，网络自己学习它需要什么样的参数。\n",
    "\n",
    "![alt text](https://github.com/MirstT/Colab_Cifar10_Image-recognition/blob/master/graph_large_attrs_key=_too_large_attrs&limit_attr_size=1024&run=.png?raw=true)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2681
    },
    "colab_type": "code",
    "id": "D7ejpLd1hz1F",
    "outputId": "cacfae10-d630-4014-a846-d1750547e2b4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:38: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (1, 1), activation=\"relu\", name=\"inception_1_/1x1\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:41: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(96, (1, 1), activation=\"relu\", name=\"inception_1_/3x3_reduce\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:44: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\", name=\"inception_1_/3x3\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:47: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (1, 1), activation=\"relu\", name=\"inception_1_/5x5_reduce\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:50: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (5, 5), activation=\"relu\", name=\"inception_1_/5x5\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:53: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(3, 3), strides=(1, 1), name=\"inception_1_/pool\", padding=\"same\")`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:56: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (1, 1), activation=\"relu\", name=\"inception_1_/pool_proj\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:38: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), activation=\"relu\", name=\"inception_2_/1x1\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:41: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), activation=\"relu\", name=\"inception_2_/3x3_reduce\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:44: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(192, (3, 3), activation=\"relu\", name=\"inception_2_/3x3\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:47: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (1, 1), activation=\"relu\", name=\"inception_2_/5x5_reduce\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:50: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(96, (5, 5), activation=\"relu\", name=\"inception_2_/5x5\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:53: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(3, 3), strides=(1, 1), name=\"inception_2_/pool\", padding=\"same\")`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:56: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (1, 1), activation=\"relu\", name=\"inception_2_/pool_proj\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:38: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(192, (1, 1), activation=\"relu\", name=\"inception_3_/1x1\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:41: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(96, (1, 1), activation=\"relu\", name=\"inception_3_/3x3_reduce\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:44: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(208, (3, 3), activation=\"relu\", name=\"inception_3_/3x3\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:47: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (1, 1), activation=\"relu\", name=\"inception_3_/5x5_reduce\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:50: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(48, (5, 5), activation=\"relu\", name=\"inception_3_/5x5\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:53: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(3, 3), strides=(1, 1), name=\"inception_3_/pool\", padding=\"same\")`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:56: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (1, 1), activation=\"relu\", name=\"inception_3_/pool_proj\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:38: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(160, (1, 1), activation=\"relu\", name=\"inception_4_/1x1\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:41: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(112, (1, 1), activation=\"relu\", name=\"inception_4_/3x3_reduce\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:44: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(224, (3, 3), activation=\"relu\", name=\"inception_4_/3x3\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:47: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (1, 1), activation=\"relu\", name=\"inception_4_/5x5_reduce\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:50: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (5, 5), activation=\"relu\", name=\"inception_4_/5x5\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:53: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(3, 3), strides=(1, 1), name=\"inception_4_/pool\", padding=\"same\")`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:56: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (1, 1), activation=\"relu\", name=\"inception_4_/pool_proj\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "inception_1_/3x3_reduce (Conv2D (None, 32, 32, 96)   384         input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "inception_1_/5x5_reduce (Conv2D (None, 32, 32, 16)   64          input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "inception_1_/pool (MaxPooling2D (None, 32, 32, 3)    0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "inception_1_/1x1 (Conv2D)       (None, 32, 32, 64)   256         input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "inception_1_/3x3 (Conv2D)       (None, 32, 32, 128)  110720      inception_1_/3x3_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "inception_1_/5x5 (Conv2D)       (None, 32, 32, 32)   12832       inception_1_/5x5_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "inception_1_/pool_proj (Conv2D) (None, 32, 32, 32)   128         inception_1_/pool[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_1_/output (Concatenat (None, 32, 32, 256)  0           inception_1_/1x1[0][0]           \n",
      "                                                                 inception_1_/3x3[0][0]           \n",
      "                                                                 inception_1_/5x5[0][0]           \n",
      "                                                                 inception_1_/pool_proj[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_1_/output_norm (Batch (None, 32, 32, 256)  1024        inception_1_/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inception_1_2x2subsample (MaxPo (None, 16, 16, 256)  0           inception_1_/output_norm[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "inception_2_/3x3_reduce (Conv2D (None, 16, 16, 128)  32896       inception_1_2x2subsample[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "inception_2_/5x5_reduce (Conv2D (None, 16, 16, 32)   8224        inception_1_2x2subsample[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "inception_2_/pool (MaxPooling2D (None, 16, 16, 256)  0           inception_1_2x2subsample[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "inception_2_/1x1 (Conv2D)       (None, 16, 16, 128)  32896       inception_1_2x2subsample[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "inception_2_/3x3 (Conv2D)       (None, 16, 16, 192)  221376      inception_2_/3x3_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "inception_2_/5x5 (Conv2D)       (None, 16, 16, 96)   76896       inception_2_/5x5_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "inception_2_/pool_proj (Conv2D) (None, 16, 16, 64)   16448       inception_2_/pool[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_2_/output (Concatenat (None, 16, 16, 480)  0           inception_2_/1x1[0][0]           \n",
      "                                                                 inception_2_/3x3[0][0]           \n",
      "                                                                 inception_2_/5x5[0][0]           \n",
      "                                                                 inception_2_/pool_proj[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_2_/output_norm (Batch (None, 16, 16, 480)  1920        inception_2_/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inception_2_2x2subsample (MaxPo (None, 8, 8, 480)    0           inception_2_/output_norm[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "inception_3_/3x3_reduce (Conv2D (None, 8, 8, 96)     46176       inception_2_2x2subsample[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "inception_3_/5x5_reduce (Conv2D (None, 8, 8, 16)     7696        inception_2_2x2subsample[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "inception_3_/pool (MaxPooling2D (None, 8, 8, 480)    0           inception_2_2x2subsample[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "inception_3_/1x1 (Conv2D)       (None, 8, 8, 192)    92352       inception_2_2x2subsample[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "inception_3_/3x3 (Conv2D)       (None, 8, 8, 208)    179920      inception_3_/3x3_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "inception_3_/5x5 (Conv2D)       (None, 8, 8, 48)     19248       inception_3_/5x5_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "inception_3_/pool_proj (Conv2D) (None, 8, 8, 64)     30784       inception_3_/pool[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_3_/output (Concatenat (None, 8, 8, 512)    0           inception_3_/1x1[0][0]           \n",
      "                                                                 inception_3_/3x3[0][0]           \n",
      "                                                                 inception_3_/5x5[0][0]           \n",
      "                                                                 inception_3_/pool_proj[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_3_/output_norm (Batch (None, 8, 8, 512)    2048        inception_3_/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inception_3_2x2subsample (MaxPo (None, 4, 4, 512)    0           inception_3_/output_norm[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "inception_4_/3x3_reduce (Conv2D (None, 4, 4, 112)    57456       inception_3_2x2subsample[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "inception_4_/5x5_reduce (Conv2D (None, 4, 4, 24)     12312       inception_3_2x2subsample[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "inception_4_/pool (MaxPooling2D (None, 4, 4, 512)    0           inception_3_2x2subsample[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "inception_4_/1x1 (Conv2D)       (None, 4, 4, 160)    82080       inception_3_2x2subsample[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "inception_4_/3x3 (Conv2D)       (None, 4, 4, 224)    226016      inception_4_/3x3_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "inception_4_/5x5 (Conv2D)       (None, 4, 4, 64)     38464       inception_4_/5x5_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "inception_4_/pool_proj (Conv2D) (None, 4, 4, 64)     32832       inception_4_/pool[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_4_/output (Concatenat (None, 4, 4, 512)    0           inception_4_/1x1[0][0]           \n",
      "                                                                 inception_4_/3x3[0][0]           \n",
      "                                                                 inception_4_/5x5[0][0]           \n",
      "                                                                 inception_4_/pool_proj[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_4_/output_norm (Batch (None, 4, 4, 512)    2048        inception_4_/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inception_4_2x2subsample (MaxPo (None, 2, 2, 512)    0           inception_4_/output_norm[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 1, 1, 512)    0           inception_4_2x2subsample[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 512)          0           average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1_128 (Dense)             (None, 128)          65664       flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1_128drop (Dropout)       (None, 128)          0           dense_1_128[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1_128norm (BatchNormaliza (None, 128)          512         dense_1_128drop[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_2_64 (Dense)              (None, 64)           8256        dense_1_128norm[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_2_64drop (Dropout)        (None, 64)           0           dense_2_64[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_2_64norm (BatchNormalizat (None, 64)           256         dense_2_64drop[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           650         dense_2_64norm[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 1,420,834\n",
      "Trainable params: 1,416,930\n",
      "Non-trainable params: 3,904\n",
      "__________________________________________________________________________________________________\n",
      "已将模型储存至../models/cifar10-nrcrt7-09:19AM_April-09-2019.json\n"
     ]
    }
   ],
   "source": [
    "import datetime # 输出模型日期后缀\n",
    "\n",
    "from keras.layers import Flatten, Activation, Conv2D, MaxPool2D, AvgPool2D, Dense, Dropout, BatchNormalization, Input, MaxPooling2D, Flatten, Activation, Conv2D, AvgPool2D, Dense, Dropout, concatenate, AveragePooling2D\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.models import Sequential\n",
    "import keras.backend as K\n",
    "from keras.regularizers import l1,l2\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "from keras.models import model_from_json, Model\n",
    "\n",
    "\n",
    "\n",
    "# 自定义全连接层\n",
    "def build_dense(input_layer, neurons_nr, dense_nr, \n",
    "                dropout=False, normalization=False, regularization='l2', dropout_ratio=0.5):\n",
    "  \n",
    "    dense = Dense(neurons_nr, kernel_regularizer=regularization, \n",
    "                  name='dense_%d_%d'%(dense_nr, neurons_nr))(input_layer)\n",
    "    \n",
    "    # 视条件而定 使用dropout/normalization\n",
    "    if dropout:\n",
    "        dense = Dropout(dropout_ratio, name='dense_%d_%ddrop'%(dense_nr, neurons_nr))(dense)\n",
    "    if normalization:\n",
    "        dense = BatchNormalization(name='dense_%d_%dnorm'%(dense_nr, neurons_nr))(dense)\n",
    "    \n",
    "    return dense\n",
    "\n",
    "  \n",
    "  \n",
    "# 构建一个Inception模型\n",
    "def build_inception_module(input_layer, features_nr, module_nr, \n",
    "                           dropout=False, normalization=False, regularization='l2', dropout_ratio=0.2): \n",
    "  \n",
    "    # feature_nr 是一个用来构建一个inception内部网络层的数组\n",
    "    # 其数据形式为: [1x1, 3x3 reduce, 3x3, 5x5 reduce, 5x5, pool proj]\n",
    "    \n",
    "    # 1*1 卷积核  \n",
    "    inception_1x1 = Conv2D(features_nr[0],1,1,border_mode='same',activation='relu',name='inception_%d_/1x1'%(module_nr),W_regularizer=l2(0.0002))(input_layer)\n",
    "    \n",
    "    # 1. 实现跨通道的交互和信息整合；2. 进行卷积核通道数的降维\n",
    "    inception_3x3_reduce = Conv2D(features_nr[1],1,1,border_mode='same',activation='relu',name='inception_%d_/3x3_reduce'%(module_nr),W_regularizer=l2(0.0002))(input_layer) \n",
    "    \n",
    "    # 3*3 卷积核\n",
    "    inception_3x3 = Conv2D(features_nr[2],3,3,border_mode='same',activation='relu',name='inception_%d_/3x3'%(module_nr),W_regularizer=l2(0.0002))(inception_3x3_reduce)\n",
    "    \n",
    "    # 1. 实现跨通道的交互和信息整合；2. 进行卷积核通道数的降维\n",
    "    inception_5x5_reduce = Conv2D(features_nr[3],1,1,border_mode='same',activation='relu',name='inception_%d_/5x5_reduce'%(module_nr),W_regularizer=l2(0.0002))(input_layer)\n",
    "    \n",
    "    # 5*5 卷积核\n",
    "    inception_5x5 = Conv2D(features_nr[4],5,5,border_mode='same',activation='relu',name='inception_%d_/5x5'%(module_nr),W_regularizer=l2(0.0002))(inception_5x5_reduce)\n",
    "    \n",
    "    # max pooling 核\n",
    "    inception_pool = MaxPooling2D(pool_size=(3,3),strides=(1,1),border_mode='same',name='inception_%d_/pool'%(module_nr))(input_layer)\n",
    "    \n",
    "    # 1. 实现跨通道的交互和信息整合；2. 进行卷积核通道数的降维\n",
    "    inception_pool_proj = Conv2D(features_nr[5],1,1,border_mode='same',activation='relu',name='inception_%d_/pool_proj'%(module_nr),W_regularizer=l2(0.0002))(inception_pool)\n",
    "    \n",
    "    # inception 输出\n",
    "    inception_output = concatenate([inception_1x1,inception_3x3,inception_5x5,inception_pool_proj],axis=3,name='inception_%d_/output'%(module_nr))\n",
    "\n",
    "    # 视条件而定 使用dropout/normalization\n",
    "    if dropout:\n",
    "        inception_output = Dropout(dropout_ratio, name='inception_%d_/output_drop'%(module_nr))(inception_output)\n",
    "    if normalization:\n",
    "        inception_output = BatchNormalization(name='inception_%d_/output_norm'%(module_nr))(inception_output)\n",
    "    \n",
    "    # maxpooling层最终输出（2*2）\n",
    "    pooled = MaxPooling2D((2,2), padding='same', name='inception_%d_2x2subsample'%(module_nr))(inception_output)\n",
    "    \n",
    "    return pooled\n",
    "\n",
    "#模型名称\n",
    "i='cifar10-nrcrt7-'+datetime.datetime.now().strftime(\"%I:%M%p_%B-%d-%Y\")\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "#在Google云盘创建储存模型与日志的文件夹（工作目录下创建）\n",
    "!mkdir -p models\n",
    "!mkdir -p logs\n",
    "\n",
    "a = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, mode='auto')#如果验证集loss值连续10个周期不下降，程序自动停止（早停法）\n",
    "b = ModelCheckpoint(monitor='val_loss', filepath='./models/'+str(i)+'.hdf5', verbose=1, save_best_only=True)#每个训练周期后，验证集loss值如果下降，则储存改模型（最终只储存最好的模型）\n",
    "c = TensorBoard(log_dir='./logs/'+str(i),\n",
    "                write_grads=True,\n",
    "                write_graph=True,\n",
    "                write_images=True,\n",
    "                batch_size=128)#保存日志文件至Google云盘中\n",
    "\n",
    "#回调函数：当评价指标不在提升时，减少学习率 （loss值连续5次没有变化时，学习率缩小十倍）\n",
    "d = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=0, mode='auto', min_delta=0.0001, cooldown=0, min_lr=0)\n",
    "\n",
    "callbacks=[a,b,c,d]\n",
    "\n",
    "#------------模型参数定义-------------------\n",
    "\n",
    "use_norm = True\n",
    "lrate = 0.001 #学习率\n",
    "\n",
    "input_img = Input(shape = (32, 32, 3), name='input') #数据输入\n",
    "\n",
    "inception_1 = build_inception_module(input_img, [64,96,128,16,32,32], 1, False, use_norm) #inception_1\n",
    "\n",
    "inception_2 = build_inception_module(inception_1, [128,128,192,32,96,64], 2, False, use_norm)#inception_2\n",
    "\n",
    "inception_3 = build_inception_module(inception_2, [192,96,208,16,48,64], 3, False, use_norm)#inception_3\n",
    "\n",
    "inception_4 = build_inception_module(inception_3, [160, 112, 224, 24, 64, 64], 4, False, use_norm)#inception_4\n",
    "\n",
    "flat_pool = AveragePooling2D(pool_size=(2, 2), padding='valid')(inception_4) #平均池化\n",
    "\n",
    "flat = Flatten()(flat_pool)\n",
    "\n",
    "dense_5 = build_dense(flat, 128, 1, True, use_norm) # 全连接层\n",
    "\n",
    "dense_6 = build_dense(dense_5, 64, 2, True, use_norm) # 全连接层\n",
    "\n",
    "out = Dense(10, activation='softmax')(dense_6) # 最后一层使用softmax激活函数\n",
    "\n",
    "model = Model(inputs = input_img, outputs = out)# 输出\n",
    "\n",
    "#-----------------------------------------------\n",
    "\n",
    "model.compile(loss='binary_crossentropy', #暂时不理解这里为什么要使用二分类的损失函数（该模型不是多标签，而是多分类，理应使用多分类中应使用的损失函数）\n",
    "              optimizer=Adam(lrate),\n",
    "              metrics=['accuracy']) #设置损失函数和优化器\n",
    "\n",
    "model.summary()\n",
    "\n",
    "#将模型转换为json文件\n",
    "model_json = model.to_json()\n",
    "with open(\"./models/\"+str(i)+\".json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "print(\"已将模型储存至\" + \"../models/\"+str(i)+\".json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sMO2DT7VljF6"
   },
   "source": [
    "## 运行内存\n",
    "模型运行时内存统计（参数）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "m2TDH7vMiCte",
    "outputId": "b0dfb340-5062-4c74-d4a7-fa4b991e784e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "内存使用 (GB): 1.47\n"
     ]
    }
   ],
   "source": [
    "def get_model_memory_usage(batch_size, model):\n",
    "    import numpy as np\n",
    "    from keras import backend as K\n",
    "\n",
    "    shapes_mem_count = 0\n",
    "    for l in model.layers:\n",
    "        single_layer_mem = 1\n",
    "        for s in l.output_shape:\n",
    "            if s is None:\n",
    "                continue\n",
    "            single_layer_mem *= s\n",
    "        shapes_mem_count += single_layer_mem\n",
    "\n",
    "    trainable_count = np.sum([K.count_params(p) for p in set(model.trainable_weights)])\n",
    "    non_trainable_count = np.sum([K.count_params(p) for p in set(model.non_trainable_weights)])\n",
    "\n",
    "    total_memory = 4.0*batch_size*(shapes_mem_count + trainable_count + non_trainable_count)\n",
    "    gbytes = np.round(total_memory / (1024.0 ** 3), 3)\n",
    "    return gbytes\n",
    "  \n",
    "print(\"内存使用 (GB):\", get_model_memory_usage(128,model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gSLsfX-EeasE"
   },
   "source": [
    "## 模型训练\n",
    "使用GPU加速训练过程，并将训练所得模型保存至Google云盘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2483
    },
    "colab_type": "code",
    "id": "6XB2xRoYiMSK",
    "outputId": "b8b0f9e1-d47a-40d2-b5ac-a698b0d849d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "40000/40000 [==============================] - 74s 2ms/step - loss: 0.5179 - acc: 0.9181 - val_loss: 0.3985 - val_acc: 0.9079\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.39853, saving model to ./models/cifar10-nrcrt7-09:19AM_April-09-2019.hdf5\n",
      "Epoch 2/100\n",
      "40000/40000 [==============================] - 72s 2ms/step - loss: 0.2953 - acc: 0.9337 - val_loss: 0.3147 - val_acc: 0.9185\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.39853 to 0.31475, saving model to ./models/cifar10-nrcrt7-09:19AM_April-09-2019.hdf5\n",
      "Epoch 3/100\n",
      "40000/40000 [==============================] - 71s 2ms/step - loss: 0.2459 - acc: 0.9416 - val_loss: 0.2898 - val_acc: 0.9257\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.31475 to 0.28980, saving model to ./models/cifar10-nrcrt7-09:19AM_April-09-2019.hdf5\n",
      "Epoch 4/100\n",
      "40000/40000 [==============================] - 72s 2ms/step - loss: 0.2246 - acc: 0.9468 - val_loss: 0.2508 - val_acc: 0.9380\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.28980 to 0.25079, saving model to ./models/cifar10-nrcrt7-09:19AM_April-09-2019.hdf5\n",
      "Epoch 5/100\n",
      "40000/40000 [==============================] - 72s 2ms/step - loss: 0.2094 - acc: 0.9511 - val_loss: 0.2697 - val_acc: 0.9305\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.25079\n",
      "Epoch 6/100\n",
      "40000/40000 [==============================] - 72s 2ms/step - loss: 0.2007 - acc: 0.9544 - val_loss: 0.2523 - val_acc: 0.9354\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.25079\n",
      "Epoch 7/100\n",
      "40000/40000 [==============================] - 72s 2ms/step - loss: 0.1943 - acc: 0.9564 - val_loss: 0.2479 - val_acc: 0.9340\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.25079 to 0.24792, saving model to ./models/cifar10-nrcrt7-09:19AM_April-09-2019.hdf5\n",
      "Epoch 8/100\n",
      "40000/40000 [==============================] - 72s 2ms/step - loss: 0.1854 - acc: 0.9588 - val_loss: 0.2338 - val_acc: 0.9395\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.24792 to 0.23377, saving model to ./models/cifar10-nrcrt7-09:19AM_April-09-2019.hdf5\n",
      "Epoch 9/100\n",
      "40000/40000 [==============================] - 72s 2ms/step - loss: 0.1806 - acc: 0.9608 - val_loss: 0.2320 - val_acc: 0.9414\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.23377 to 0.23200, saving model to ./models/cifar10-nrcrt7-09:19AM_April-09-2019.hdf5\n",
      "Epoch 10/100\n",
      "40000/40000 [==============================] - 72s 2ms/step - loss: 0.1760 - acc: 0.9626 - val_loss: 0.2384 - val_acc: 0.9365\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.23200\n",
      "Epoch 11/100\n",
      "40000/40000 [==============================] - 72s 2ms/step - loss: 0.1724 - acc: 0.9636 - val_loss: 0.2319 - val_acc: 0.9420\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.23200 to 0.23194, saving model to ./models/cifar10-nrcrt7-09:19AM_April-09-2019.hdf5\n",
      "Epoch 12/100\n",
      "40000/40000 [==============================] - 73s 2ms/step - loss: 0.1691 - acc: 0.9651 - val_loss: 0.2177 - val_acc: 0.9457\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.23194 to 0.21770, saving model to ./models/cifar10-nrcrt7-09:19AM_April-09-2019.hdf5\n",
      "Epoch 13/100\n",
      "40000/40000 [==============================] - 72s 2ms/step - loss: 0.1652 - acc: 0.9663 - val_loss: 0.2090 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.21770 to 0.20899, saving model to ./models/cifar10-nrcrt7-09:19AM_April-09-2019.hdf5\n",
      "Epoch 14/100\n",
      "40000/40000 [==============================] - 72s 2ms/step - loss: 0.1636 - acc: 0.9669 - val_loss: 0.2001 - val_acc: 0.9531\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.20899 to 0.20011, saving model to ./models/cifar10-nrcrt7-09:19AM_April-09-2019.hdf5\n",
      "Epoch 15/100\n",
      "40000/40000 [==============================] - 72s 2ms/step - loss: 0.1601 - acc: 0.9684 - val_loss: 0.2126 - val_acc: 0.9490\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.20011\n",
      "Epoch 16/100\n",
      "40000/40000 [==============================] - 73s 2ms/step - loss: 0.1568 - acc: 0.9691 - val_loss: 0.2138 - val_acc: 0.9515\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.20011\n",
      "Epoch 17/100\n",
      "40000/40000 [==============================] - 73s 2ms/step - loss: 0.1547 - acc: 0.9699 - val_loss: 0.2084 - val_acc: 0.9519\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.20011\n",
      "Epoch 18/100\n",
      "40000/40000 [==============================] - 73s 2ms/step - loss: 0.1540 - acc: 0.9703 - val_loss: 0.2122 - val_acc: 0.9496\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.20011\n",
      "Epoch 19/100\n",
      "40000/40000 [==============================] - 73s 2ms/step - loss: 0.1493 - acc: 0.9720 - val_loss: 0.2642 - val_acc: 0.9355\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.20011\n",
      "Epoch 20/100\n",
      "40000/40000 [==============================] - 73s 2ms/step - loss: 0.1186 - acc: 0.9821 - val_loss: 0.1461 - val_acc: 0.9697\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.20011 to 0.14614, saving model to ./models/cifar10-nrcrt7-09:19AM_April-09-2019.hdf5\n",
      "Epoch 21/100\n",
      "40000/40000 [==============================] - 73s 2ms/step - loss: 0.1000 - acc: 0.9869 - val_loss: 0.1400 - val_acc: 0.9707\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.14614 to 0.13998, saving model to ./models/cifar10-nrcrt7-09:19AM_April-09-2019.hdf5\n",
      "Epoch 22/100\n",
      "40000/40000 [==============================] - 73s 2ms/step - loss: 0.0897 - acc: 0.9896 - val_loss: 0.1370 - val_acc: 0.9704\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.13998 to 0.13705, saving model to ./models/cifar10-nrcrt7-09:19AM_April-09-2019.hdf5\n",
      "Epoch 23/100\n",
      "40000/40000 [==============================] - 73s 2ms/step - loss: 0.0821 - acc: 0.9912 - val_loss: 0.1356 - val_acc: 0.9710\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.13705 to 0.13556, saving model to ./models/cifar10-nrcrt7-09:19AM_April-09-2019.hdf5\n",
      "Epoch 24/100\n",
      "40000/40000 [==============================] - 73s 2ms/step - loss: 0.0757 - acc: 0.9927 - val_loss: 0.1363 - val_acc: 0.9705\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.13556\n",
      "Epoch 25/100\n",
      "40000/40000 [==============================] - 72s 2ms/step - loss: 0.0700 - acc: 0.9942 - val_loss: 0.1378 - val_acc: 0.9703\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.13556\n",
      "Epoch 26/100\n",
      "40000/40000 [==============================] - 72s 2ms/step - loss: 0.0656 - acc: 0.9951 - val_loss: 0.1375 - val_acc: 0.9700\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.13556\n",
      "Epoch 27/100\n",
      "40000/40000 [==============================] - 72s 2ms/step - loss: 0.0614 - acc: 0.9962 - val_loss: 0.1413 - val_acc: 0.9692\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.13556\n",
      "Epoch 28/100\n",
      "40000/40000 [==============================] - 72s 2ms/step - loss: 0.0588 - acc: 0.9966 - val_loss: 0.1447 - val_acc: 0.9694\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.13556\n",
      "Epoch 29/100\n",
      "40000/40000 [==============================] - 72s 2ms/step - loss: 0.0543 - acc: 0.9980 - val_loss: 0.1423 - val_acc: 0.9705\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.13556\n",
      "Epoch 30/100\n",
      "40000/40000 [==============================] - 72s 2ms/step - loss: 0.0531 - acc: 0.9983 - val_loss: 0.1423 - val_acc: 0.9707\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.13556\n",
      "Epoch 31/100\n",
      "40000/40000 [==============================] - 71s 2ms/step - loss: 0.0523 - acc: 0.9985 - val_loss: 0.1429 - val_acc: 0.9706\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.13556\n",
      "Epoch 32/100\n",
      "40000/40000 [==============================] - 71s 2ms/step - loss: 0.0517 - acc: 0.9986 - val_loss: 0.1433 - val_acc: 0.9705\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.13556\n",
      "Epoch 33/100\n",
      "40000/40000 [==============================] - 72s 2ms/step - loss: 0.0512 - acc: 0.9987 - val_loss: 0.1432 - val_acc: 0.9707\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.13556\n",
      "Epoch 00033: early stopping\n",
      "10000/10000 [==============================] - 8s 772us/step\n",
      "准确率（测试集）:  96.8780002784729 %\n",
      "已将模型与日志拷贝至Google云盘\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "  model.fit(x_train, y_train_cat, batch_size=128, epochs=100, validation_split=0.2,verbose=1,callbacks=callbacks)  # 开始训练 100个周期\n",
    "\n",
    "  \n",
    "  \n",
    "result = model.evaluate(x_test, y_test_cat)\n",
    "\n",
    "print(\"准确率（测试集）: \",result[1]*100,\"%\")\n",
    "\n",
    "#将模型与日志拷贝至Google云盘\n",
    "!cp -R models Advanced_Data_Analysis\n",
    "!cp -R logs Advanced_Data_Analysis\n",
    "\n",
    "print(\"已将模型与日志拷贝至Google云盘\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZLMzGIZMenWt"
   },
   "source": [
    "## 模型的准确率和loss值\n",
    "\n",
    "### 训练集\n",
    "![alt text](https://github.com/MirstT/Colab_Cifar10_Image-recognition/blob/master/res/WH_2019-04-09_18-17-40.png?raw=true)\n",
    "![alt text](https://github.com/MirstT/Colab_Cifar10_Image-recognition/blob/master/res/WH_2019-04-09_18-17-48.png?raw=true)\n",
    "\n",
    "### 验证集\n",
    "![alt text](https://github.com/MirstT/Colab_Cifar10_Image-recognition/blob/master/res/WH_2019-04-09_18-17-57.png?raw=true)\n",
    "![alt text](https://github.com/MirstT/Colab_Cifar10_Image-recognition/blob/master/res/WH_2019-04-09_18-18-05.png?raw=true)\n",
    "\n",
    "*注：程序运行至第32个周期时自动停止*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ItkPGXmeedDB"
   },
   "source": [
    "## 模型测试\n",
    "cifar10-nrcrt7-09:19AM_April-09-2019.hdf5\n",
    "\n",
    "导入模型，在测试集上进行测试，输出loss值和准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "b_YyW_4MkCIE",
    "outputId": "b53dc153-59b7-47ad-d1dd-86f12075998d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 8s 764us/step\n",
      "[0.1395178472995758, 0.969710001373291]\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('./models/cifar10-nrcrt7-09:19AM_April-09-2019.hdf5')\n",
    "\n",
    "result = model.evaluate(x_test, y_test_cat)\n",
    "\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Cifar_10_图像识别.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
